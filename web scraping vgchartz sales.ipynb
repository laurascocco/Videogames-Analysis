{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "thGaNzfXg_Ey"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup, element\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from http.client import IncompleteRead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b3Ft9q54hdfB"
      },
      "outputs": [],
      "source": [
        "class VideoGameScraper:\n",
        "    def __init__(self, url1, url2, start_page, end_page):\n",
        "        self.url1 = url1\n",
        "        self.url2 = url2\n",
        "        self.start_page = start_page\n",
        "        self.end_page = end_page\n",
        "        self.session = requests.Session()\n",
        "        self.failed_game_links = []  # List error games\n",
        "\n",
        "    def scrape(self):\n",
        "        videogame = []\n",
        "        platform = []\n",
        "        editor = []\n",
        "        developer = []\n",
        "        sales_na = []\n",
        "        sales_eu = []\n",
        "        sales_jp = []\n",
        "        sales_others = []\n",
        "        sales_tot = []\n",
        "        release_date = []\n",
        "        genre = []\n",
        "\n",
        "        for page in range(self.start_page, self.end_page + 1):\n",
        "            try:\n",
        "                surl = self.url1 + str(page) + self.url2\n",
        "                response = self.session.get(surl)\n",
        "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "                videogame_tag = list(filter(lambda x: 'href' in x.attrs and x.attrs['href'].startswith('https://www.vgchartz.com/game/'),soup.find_all(\"a\")))\n",
        "\n",
        "                for tag in videogame_tag:\n",
        "                    videogame_name = tag.contents[0][:-4]\n",
        "                    print(\"Videogame Name:\", videogame_name)\n",
        "                    videogame.append(videogame_name)\n",
        "\n",
        "                    data = tag.parent.parent.find_all(\"td\")\n",
        "                    platform.append(data[3].find(\"img\").attrs[\"alt\"])\n",
        "                    editor.append(data[4].string)\n",
        "                    developer.append(data[5].string)\n",
        "                    sales_na.append(float(data[7].string[:-1]) if not data[7].string.startswith(\"N/A\") else np.nan)\n",
        "                    sales_eu.append(float(data[8].string[:-1]) if not data[8].string.startswith(\"N/A\") else np.nan)\n",
        "                    sales_jp.append(float(data[9].string[:-1]) if not data[9].string.startswith(\"N/A\") else np.nan)\n",
        "                    sales_others.append(float(data[10].string[:-1]) if not data[10].string.startswith(\"N/A\") else np.nan)\n",
        "                    sales_tot.append(float(data[6].string[:-1]) if not data[6].string.startswith(\"N/A\") else np.nan)\n",
        "\n",
        "                    tag_date_element = data[11].string\n",
        "                    release_date_value = tag_date_element.strip() if tag_date_element else None\n",
        "                    release_date.append(release_date_value)\n",
        "\n",
        "                    genre_url = tag.attrs['href']\n",
        "                    attempts = 0\n",
        "                    while attempts < 3:  \n",
        "                        try:\n",
        "                            genre_link = urllib.request.urlopen(genre_url).read()\n",
        "                            genre_soup = BeautifulSoup(genre_link, \"html.parser\")\n",
        "\n",
        "                            h2s = genre_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
        "\n",
        "                            genre_tag = element.Tag\n",
        "                            for h2 in h2s:\n",
        "                                if h2.string == 'Genre':\n",
        "                                    genre_tag = h2\n",
        "                                    \n",
        "                            genre.append(genre_tag.next_sibling.string)\n",
        "                            break  \n",
        "                        except (IncompleteRead, ValueError) as e:\n",
        "                            attempts += 1\n",
        "                            print(f\"Errore durante la lettura della risposta HTTP: {e}. Riprovo ({attempts}/3)\")\n",
        "                            if attempts == 3:\n",
        "                                print(f\"Impossibile recuperare i dati per il gioco: {videogame_name}\")\n",
        "                                self.failed_game_links.append(genre_url)  \n",
        "                                break  \n",
        "                            continue  \n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Errore durante lo scraping: {e}\")\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"videogame\": videogame,\n",
        "            \"platform\": platform,\n",
        "            \"editor\": editor,\n",
        "            \"developer\": developer,\n",
        "            \"sales_na\": sales_na,\n",
        "            \"sales_eu\": sales_eu,\n",
        "            \"sales_jp\": sales_jp,\n",
        "            \"sales_otras\": sales_others,\n",
        "            \"sales_tot\": sales_tot,\n",
        "            \"release\": release_date,\n",
        "            \"genre\": genre\n",
        "        })\n",
        "\n",
        "        return df, self.failed_game_links\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    url1 = \"https://www.vgchartz.com/games/games.php?page=\"\n",
        "    url2 = '&results=1000&order=Sales&ownership=Both&direction=DESC&showtotalsales=1' \n",
        "    url2 += '&shownasales=1&showpalsales=1&showjapansales=1&showothersales=1&showpublisher=1&showdeveloper=1'\n",
        "    url2 += '&showreleasedate=1&showlastupdate=0&showvgchartzscore=0&showcriticscore=0&showuserscore=0&showshipped=0'\n",
        "\n",
        "scraper = VideoGameScraper(url1, url2, start_page=1, end_page=65) # 65 pages if 1000 entries are displayed in each page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = scraper.scrape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data = df[0]\n",
        "\n",
        "# New DataFrame with data\n",
        "new_df = pd.DataFrame(df_data)\n",
        "\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1hPCfQP7BvA"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv('vgchartz_sales.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
